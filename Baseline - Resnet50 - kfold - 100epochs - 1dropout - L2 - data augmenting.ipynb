{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "on-xhn6xYqDo"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "Zq5nydmlidrt"
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import glob\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications import *\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.models import *\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import *\n",
    "from tensorflow.keras.callbacks import *\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras import models\n",
    "from tensorflow.keras import layers\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "CLASS_NAMES= ['healthy', 'mild', 'moderate', 'severe']\n",
    "IMG_HEIGHT = 128\n",
    "IMG_WIDTH = 128\n",
    "CHANNELS = 3\n",
    "NUM_CLASSES = len(CLASS_NAMES)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yfeZvMIEDOwS"
   },
   "source": [
    "# **ResNET**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "98Cf8ZeSEbCU"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TOTAL_IMAGES =  2368\n"
     ]
    }
   ],
   "source": [
    "#load data\n",
    "data_x = np.load('data_x_aumentated_normalized.npy') #images\n",
    "data_y = np.load('data_y_aumentated_normalized.npy') #labels\n",
    "TOTAL_IMAGES = len(data_y)\n",
    "print(\"TOTAL_IMAGES = \", TOTAL_IMAGES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "VALIDATION_PERCENTAGE = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_size = int(VALIDATION_PERCENTAGE * TOTAL_IMAGES)\n",
    "\n",
    "validation_x = data_x[:validation_size] #taking validation images from original data\n",
    "validation_y = data_y[:validation_size]\n",
    "data_x = data_x[validation_size:] #removing validation images from original data\n",
    "data_y = data_y[validation_size:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Splitting data in train - validation - test**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "BiIjdq89J1uJ"
   },
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Activation, Dropout, Flatten, Conv2D, MaxPooling2D\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.regularizers import l1\n",
    "from tensorflow.keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "j0vHxhMjLyhJ",
    "outputId": "e5ec2803-8f76-4719-e279-27c52eb8d72d"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.layers import Input, Add, Dense, Activation, ZeroPadding2D, BatchNormalization, Flatten, Conv2D, AveragePooling2D, MaxPooling2D, GlobalMaxPooling2D\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from IPython.display import SVG\n",
    "import scipy.misc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.keras.backend as K\n",
    "from tensorflow.keras import models\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from tensorflow.keras.applications import EfficientNetB0\n",
    "# from tensorflow.keras.applications import EfficientNetB1\n",
    "# from tensorflow.keras.applications import EfficientNetB2\n",
    "# from tensorflow.keras.applications import EfficientNetB3\n",
    "# from tensorflow.keras.applications import EfficientNetB4\n",
    "# from tensorflow.keras.applications import EfficientNetB5\n",
    "# from tensorflow.keras.applications import EfficientNetB6\n",
    "# from tensorflow.keras.applications import EfficientNetB7\n",
    "# from tensorflow.keras.applications import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tmcle\\.conda\\envs\\tf\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "adam = tf.keras.optimizers.Adam(lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def define_model():\n",
    "    K.set_image_data_format('channels_last')\n",
    "    K.set_learning_phase(1)\n",
    "    model = tf.keras.applications.ResNet50(\n",
    "        include_top=False,\n",
    "        weights=\"imagenet\",\n",
    "        input_tensor=None,\n",
    "        input_shape=(IMG_HEIGHT,IMG_WIDTH, CHANNELS),\n",
    "        pooling=None,\n",
    "        classes=NUM_CLASSES,\n",
    "        # classifier_activation=\"softmax\",\n",
    "        # **kwargs\n",
    "    )\n",
    "    new_model = models.Sequential()\n",
    "    new_model.add(model)\n",
    "    #3rd conv layer\n",
    "    new_model.add(tf.keras.layers.Conv2D(32, 3, padding=\"same\"))\n",
    "    new_model.add(tf.keras.layers.BatchNormalization())\n",
    "    new_model.add(tf.keras.layers.Activation(\"relu\"))\n",
    "    new_model.add(tf.keras.layers.MaxPooling2D(2))\n",
    "    #4th conv layer\n",
    "    new_model.add(tf.keras.layers.Conv2D(64, 3, padding=\"same\"))\n",
    "    new_model.add(tf.keras.layers.BatchNormalization())\n",
    "    new_model.add(tf.keras.layers.Activation(\"relu\"))\n",
    "    new_model.add(tf.keras.layers.MaxPooling2D(2))\n",
    "    #Flatten Layer\n",
    "    new_model.add(tf.keras.layers.Flatten())\n",
    "\n",
    "    new_model.add(tf.keras.layers.Dense(128, kernel_regularizer =tf.keras.regularizers.l2( l=0.01)))\n",
    "    new_model.add(tf.keras.layers.BatchNormalization())\n",
    "    new_model.add(tf.keras.layers.Activation(\"relu\"))\n",
    "    new_model.add(tf.keras.layers.Dropout(0.2))\n",
    "    #new_model.add(tf.keras.layers.l2( l=0.01))\n",
    "    #new_model.add(layers.GlobalAveragePooling2D())\n",
    "    #output Dense Layer\n",
    "    new_model.add(tf.keras.layers.Dense(NUM_CLASSES))\n",
    "    new_model.add(tf.keras.layers.Activation('softmax'))\n",
    "    return new_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "kfold = KFold(n_splits=5, shuffle=True, random_state=7)\n",
    "cvscores = []\n",
    "epochs = 100\n",
    "num_classes = 2\n",
    "num_kfold=1\n",
    "all_models = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tmcle\\.conda\\envs\\tf\\lib\\site-packages\\keras\\backend.py:451: UserWarning: `tf.keras.backend.set_learning_phase` is deprecated and will be removed after 2020-10-11. To update it, simply pass a True/False value to the `training` argument of the `__call__` method of your layer or model.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "54/54 - 27s - loss: 1.6480 - accuracy: 0.6457 - val_loss: 3.2377 - val_accuracy: 0.2717 - 27s/epoch - 500ms/step\n",
      "Epoch 2/100\n",
      "54/54 - 16s - loss: 1.0713 - accuracy: 0.8334 - val_loss: 4.5863 - val_accuracy: 0.2529 - 16s/epoch - 293ms/step\n",
      "Epoch 3/100\n",
      "54/54 - 16s - loss: 0.7861 - accuracy: 0.8979 - val_loss: 13.3818 - val_accuracy: 0.2529 - 16s/epoch - 293ms/step\n",
      "Epoch 4/100\n",
      "54/54 - 16s - loss: 0.6578 - accuracy: 0.8979 - val_loss: 3.9136 - val_accuracy: 0.2717 - 16s/epoch - 293ms/step\n",
      "Epoch 5/100\n",
      "54/54 - 16s - loss: 0.5204 - accuracy: 0.9243 - val_loss: 4.5529 - val_accuracy: 0.2717 - 16s/epoch - 294ms/step\n",
      "Epoch 6/100\n",
      "54/54 - 16s - loss: 0.3831 - accuracy: 0.9431 - val_loss: 5.3467 - val_accuracy: 0.2717 - 16s/epoch - 296ms/step\n",
      "Epoch 7/100\n",
      "54/54 - 16s - loss: 0.2902 - accuracy: 0.9695 - val_loss: 6.6734 - val_accuracy: 0.2717 - 16s/epoch - 299ms/step\n",
      "Epoch 8/100\n",
      "54/54 - 16s - loss: 0.2330 - accuracy: 0.9707 - val_loss: 4.0340 - val_accuracy: 0.2717 - 16s/epoch - 298ms/step\n",
      "Epoch 9/100\n"
     ]
    }
   ],
   "source": [
    "for train, test in kfold.split (data_x, data_y):\n",
    "    new_model = define_model()\n",
    "\n",
    "    new_model.compile(loss='sparse_categorical_crossentropy', metrics=['accuracy'], optimizer=adam)\n",
    "    history = new_model.fit(data_x[train], data_y[train],\n",
    "                                epochs=epochs,verbose=2,validation_data=(data_x[test], data_y[test]), shuffle=False)\n",
    "\n",
    "    new_model.history.history.keys()\n",
    "    f,ax=plt.subplots(2,1,figsize=(10,10)) \n",
    "\n",
    "    #Assigning the first subplot to graph training loss and validation loss\n",
    "    ax[0].plot(new_model.history.history['loss'],color='b',label='Training Loss')\n",
    "    ax[0].plot(new_model.history.history['val_loss'],color='r',label='Validation Loss')\n",
    "\n",
    "    #Plotting the training accuracy and validation accuracy\n",
    "    ax[1].plot(new_model.history.history['accuracy'],color='b',label='Training  Accuracy')\n",
    "    ax[1].plot(new_model.history.history['val_accuracy'],color='r',label='Validation Accuracy')\n",
    "\n",
    "    plt.legend()\n",
    "    print('Accuracy Score = ',np.max(history.history['val_accuracy']))\n",
    "\n",
    "    scores = new_model.evaluate(validation_x,validation_y,verbose=0)\n",
    "    print(\"%s: %.2f%%\" %(new_model.metrics_names[1],scores[1]*100))\n",
    "    cvscores.append(scores[1]*100)\n",
    "    \n",
    "    new_model.save(f'resnet50_100epochs_augmented_kfold_{str(num_kfold)}.npy')\n",
    "    all_models.append(new_model)\n",
    "    num_kfold = num_kfold + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"%.2f%% (+/- %.2f%%)\" %(np.mean(cvscores),np.std(cvscores)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Random forest - flatting**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import metrics\n",
    "cvscores_rf = []\n",
    "for new_model in all_models:\n",
    "    new_model_rf = keras.Model(inputs=new_model.input, outputs=new_model.get_layer(index=9).output)\n",
    "    featureVector = new_model_rf.predict(data_x)\n",
    "    featureVector2 = new_model_rf.predict(validation_x)\n",
    "    clf=RandomForestClassifier(n_estimators=100)\n",
    "    clf.fit(featureVector,data_y)\n",
    "    y_pred=clf.predict(featureVector2)\n",
    "    score = metrics.accuracy_score(validation_y, y_pred)\n",
    "    cvscores_rf.append(score)\n",
    "    print(\"Accuracy:\",score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"%.2f%% (+/- %.2f%%)\" %(np.mean(cvscores_rf),np.std(cvscores_rf)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "v2tUu9UW4S_S"
   },
   "source": [
    "# **Testes**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-02BWWgF4V9h"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "accuracy = model_trained.history['acc']\n",
    "val_accuracy = model_trained.history['val_acc']\n",
    "loss = model_trained.history['loss']\n",
    "val_loss = model_trained.history['val_loss']\n",
    "epochs = range(len(accuracy))\n",
    "plt.plot(epochs, accuracy, 'b', label='Acurácia de treino')\n",
    "plt.plot(epochs, val_accuracy, 'g', label='Acurácia de validação')\n",
    "plt.title('Acurácia de treino e validação')\n",
    "plt.legend()\n",
    "plt.figure()\n",
    "plt.plot(epochs, loss, 'b', label='Perda no treino')\n",
    "plt.plot(epochs, val_loss, 'g', label='Perda na validação')\n",
    "plt.title('Perda na validação e treino')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "On7_hNmrOysp"
   },
   "outputs": [],
   "source": [
    "#avalia a fase de teste\n",
    "\n",
    "model_loss, model_accuracy = new_model.evaluate(test_x, test_y, verbose=1)\n",
    "\n",
    "#mostra o resultado\n",
    "print('Test loss:', model_loss)\n",
    "print('Test accuracy:', model_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uGYRlhnq8wsF"
   },
   "outputs": [],
   "source": [
    "#faz a predição das imagens\n",
    "\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "pred = new_model.predict(test_x, verbose=0)\n",
    "\n",
    "pred_probs = np.argmax(pred,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Vt4jZ2jB8ygE"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9gx5yvuU84UC"
   },
   "outputs": [],
   "source": [
    "cm = confusion_matrix(test_y, pred_probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NUrE8yfU86OL"
   },
   "outputs": [],
   "source": [
    "#gera os valores de falso positivo, falso negativo, verdadeiro positivo e verdadeiro negativo\n",
    "fp = cm.sum(axis=0) - np.diag(cm)  \n",
    "fn = cm.sum(axis=1) - np.diag(cm)\n",
    "tp = np.diag(cm)\n",
    "tn = cm.sum() - (fp + fn + tp)\n",
    "\n",
    "f1score = f1_score(test_y, pred_probs, average='weighted')\n",
    "sensitivity = tp / (tp + fn)\n",
    "specificity = tn / (tn + fp)\n",
    "accuracy    = (tp + tn) / (tp + tn + fp + fn)\n",
    "precision   = tp / (tp + fp)\n",
    "\n",
    "\n",
    "print(\"F1 Score:\", f1score)\n",
    "print(\"Sensitivity:\", sensitivity)\n",
    "print(\"Specificity:\", specificity)\n",
    "print(\"Precision:  \", precision)\n",
    "print(\"Accuracy:   \", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "covid_alex_holdout_cropping_tgo.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
