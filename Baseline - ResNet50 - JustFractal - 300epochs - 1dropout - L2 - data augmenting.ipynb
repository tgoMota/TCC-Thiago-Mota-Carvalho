{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "on-xhn6xYqDo"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "Zq5nydmlidrt"
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import glob\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications import *\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.models import *\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import *\n",
    "from tensorflow.keras.callbacks import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "CLASS_NAMES= ['healthy', 'mild', 'moderate', 'severe']\n",
    "IMG_HEIGHT = 128\n",
    "IMG_WIDTH = 128\n",
    "CHANNELS = 3\n",
    "NUM_CLASSES = len(CLASS_NAMES)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yfeZvMIEDOwS"
   },
   "source": [
    "# **ResNET**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "98Cf8ZeSEbCU"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TOTAL_IMAGES =  3848\n"
     ]
    }
   ],
   "source": [
    "#load data\n",
    "data_x = np.load('just_fractal_data_x_original.npy') #images\n",
    "data_y = np.load('just_fractal_data_y_original.npy') #labels\n",
    "TOTAL_IMAGES = len(data_y)\n",
    "print(\"TOTAL_IMAGES = \", TOTAL_IMAGES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scale pixels\n",
    "def prep_pixels(train, test, validation):\n",
    "    # convert from integers to floats\n",
    "    train_norm = train.astype('float32')\n",
    "    test_norm = test.astype('float32')\n",
    "    validation_norm = validation.astype('float32')\n",
    "    # normalize to range 0-1\n",
    "    train_norm = train_norm / 255.0\n",
    "    test_norm = test_norm / 255.0\n",
    "    validation_norm = validation_norm / 255.0\n",
    "    # return normalized images\n",
    "    return train_norm, test_norm, validation_norm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Splitting data in train - validation - test**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#percentage of the dataset which will be on TRAIN - TEST - VALIDATION\n",
    "TRAIN_PERCENTAGE = 0.8\n",
    "TEST_PERCENTAGE = 0.1\n",
    "VALIDATION_PERCENTAGE = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = int(TRAIN_PERCENTAGE * TOTAL_IMAGES)\n",
    "test_size = int(TEST_PERCENTAGE * TOTAL_IMAGES)\n",
    "validation_size = int(VALIDATION_PERCENTAGE * TOTAL_IMAGES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = data_x[:train_size]\n",
    "train_y = data_y[:train_size]\n",
    "data_x = data_x[train_size:]\n",
    "data_y = data_y[train_size:]\n",
    "\n",
    "test_x = data_x[:test_size]\n",
    "test_y = data_y[:test_size]\n",
    "data_x = data_x[test_size:]\n",
    "data_y = data_y[test_size:]\n",
    "\n",
    "validation_x = data_x #all the remainder we can let on validation\n",
    "validation_y = data_y\n",
    "del data_x\n",
    "del data_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_size =  3078\n",
      "test_size =  384\n",
      "validation_size =  386\n"
     ]
    }
   ],
   "source": [
    "print(\"train_size = \", len(train_y))\n",
    "print(\"test_size = \", len(test_y))\n",
    "print(\"validation_size = \", len(validation_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x, test_x, validation_x = prep_pixels(train_x, test_x, validation_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "BiIjdq89J1uJ"
   },
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Activation, Dropout, Flatten, Conv2D, MaxPooling2D\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.regularizers import l1\n",
    "from tensorflow.keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "j0vHxhMjLyhJ",
    "outputId": "e5ec2803-8f76-4719-e279-27c52eb8d72d"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.layers import Input, Add, Dense, Activation, ZeroPadding2D, BatchNormalization, Flatten, Conv2D, AveragePooling2D, MaxPooling2D, GlobalMaxPooling2D\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from IPython.display import SVG\n",
    "import scipy.misc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from tensorflow.keras.applications import EfficientNetB0\n",
    "# from tensorflow.keras.applications import EfficientNetB1\n",
    "# from tensorflow.keras.applications import EfficientNetB2\n",
    "# from tensorflow.keras.applications import EfficientNetB3\n",
    "# from tensorflow.keras.applications import EfficientNetB4\n",
    "# from tensorflow.keras.applications import EfficientNetB5\n",
    "# from tensorflow.keras.applications import EfficientNetB6\n",
    "# from tensorflow.keras.applications import EfficientNetB7\n",
    "# from tensorflow.keras.applications import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tmcle\\.conda\\envs\\tf\\lib\\site-packages\\keras\\backend.py:451: UserWarning: `tf.keras.backend.set_learning_phase` is deprecated and will be removed after 2020-10-11. To update it, simply pass a True/False value to the `training` argument of the `__call__` method of your layer or model.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import tensorflow.keras.backend as K\n",
    "K.set_image_data_format('channels_last')\n",
    "K.set_learning_phase(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.applications.ResNet50(\n",
    "    include_top=False,\n",
    "    weights=\"imagenet\",\n",
    "    input_tensor=None,\n",
    "    input_shape=(IMG_HEIGHT,IMG_WIDTH, CHANNELS),\n",
    "    pooling=None,\n",
    "    classes=NUM_CLASSES,\n",
    "   # classifier_activation=\"softmax\",\n",
    "#    **kwargs\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tmcle\\.conda\\envs\\tf\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras import models\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "new_model = models.Sequential()\n",
    "new_model.add(model)\n",
    "#3rd conv layer\n",
    "new_model.add(tf.keras.layers.Conv2D(32, 3, padding=\"same\"))\n",
    "new_model.add(tf.keras.layers.BatchNormalization())\n",
    "new_model.add(tf.keras.layers.Activation(\"relu\"))\n",
    "new_model.add(tf.keras.layers.MaxPooling2D(2))\n",
    "#4th conv layer\n",
    "new_model.add(tf.keras.layers.Conv2D(64, 3, padding=\"same\"))\n",
    "new_model.add(tf.keras.layers.BatchNormalization())\n",
    "new_model.add(tf.keras.layers.Activation(\"relu\"))\n",
    "new_model.add(tf.keras.layers.MaxPooling2D(2))\n",
    "#Flatten Layer\n",
    "new_model.add(tf.keras.layers.Flatten())\n",
    "\n",
    "new_model.add(tf.keras.layers.Dense(128, kernel_regularizer =tf.keras.regularizers.l2( l=0.01)))\n",
    "new_model.add(tf.keras.layers.BatchNormalization())\n",
    "new_model.add(tf.keras.layers.Activation(\"relu\"))\n",
    "new_model.add(tf.keras.layers.Dropout(0.2))\n",
    "#new_model.add(tf.keras.layers.l2( l=0.01))\n",
    "#new_model.add(layers.GlobalAveragePooling2D())\n",
    "#output Dense Layer\n",
    "new_model.add(tf.keras.layers.Dense(NUM_CLASSES))\n",
    "new_model.add(tf.keras.layers.Activation('softmax'))\n",
    "adam = tf.keras.optimizers.Adam(lr=0.001)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " resnet50 (Functional)       (None, 4, 4, 2048)        23587712  \n",
      "                                                                 \n",
      " conv2d (Conv2D)             (None, 4, 4, 32)          589856    \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 4, 4, 32)         128       \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " activation (Activation)     (None, 4, 4, 32)          0         \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 2, 2, 32)         0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 2, 2, 64)          18496     \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 2, 2, 64)         256       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " activation_1 (Activation)   (None, 2, 2, 64)          0         \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 1, 1, 64)         0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 64)                0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 128)               8320      \n",
      "                                                                 \n",
      " batch_normalization_2 (Batc  (None, 128)              512       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " activation_2 (Activation)   (None, 128)               0         \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 128)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 4)                 516       \n",
      "                                                                 \n",
      " activation_3 (Activation)   (None, 4)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 24,205,796\n",
      "Trainable params: 24,152,228\n",
      "Non-trainable params: 53,568\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "new_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "97/97 - 40s - loss: 2.2527 - acc: 0.2596 - val_loss: 4.5371 - val_acc: 0.2409 - 40s/epoch - 411ms/step\n",
      "Epoch 2/300\n",
      "97/97 - 28s - loss: 1.9724 - acc: 0.2612 - val_loss: 1.8141 - val_acc: 0.2358 - 28s/epoch - 289ms/step\n",
      "Epoch 3/300\n",
      "97/97 - 29s - loss: 1.8247 - acc: 0.2619 - val_loss: 1.6927 - val_acc: 0.2358 - 29s/epoch - 296ms/step\n",
      "Epoch 4/300\n",
      "97/97 - 29s - loss: 1.7056 - acc: 0.2365 - val_loss: 1.6098 - val_acc: 0.2772 - 29s/epoch - 294ms/step\n",
      "Epoch 5/300\n",
      "97/97 - 28s - loss: 1.6235 - acc: 0.2476 - val_loss: 1.5513 - val_acc: 0.2461 - 28s/epoch - 290ms/step\n",
      "Epoch 6/300\n",
      "97/97 - 28s - loss: 1.5625 - acc: 0.2680 - val_loss: 1.5084 - val_acc: 0.2461 - 28s/epoch - 290ms/step\n",
      "Epoch 7/300\n",
      "97/97 - 28s - loss: 1.5256 - acc: 0.2355 - val_loss: 1.4760 - val_acc: 0.2772 - 28s/epoch - 289ms/step\n",
      "Epoch 8/300\n",
      "97/97 - 28s - loss: 1.5035 - acc: 0.2443 - val_loss: 1.4522 - val_acc: 0.2772 - 28s/epoch - 290ms/step\n",
      "Epoch 9/300\n",
      "97/97 - 28s - loss: 1.4856 - acc: 0.2469 - val_loss: 21.1129 - val_acc: 0.2176 - 28s/epoch - 290ms/step\n",
      "Epoch 10/300\n",
      "97/97 - 28s - loss: 1.4635 - acc: 0.2482 - val_loss: 6.0680 - val_acc: 0.2202 - 28s/epoch - 293ms/step\n",
      "Epoch 11/300\n",
      "97/97 - 29s - loss: 1.4498 - acc: 0.2550 - val_loss: 1.4154 - val_acc: 0.2435 - 29s/epoch - 294ms/step\n",
      "Epoch 12/300\n",
      "97/97 - 29s - loss: 1.4369 - acc: 0.2550 - val_loss: 1.4115 - val_acc: 0.2409 - 29s/epoch - 296ms/step\n",
      "Epoch 13/300\n",
      "97/97 - 29s - loss: 1.4377 - acc: 0.2420 - val_loss: 1.4315 - val_acc: 0.2591 - 29s/epoch - 297ms/step\n",
      "Epoch 14/300\n",
      "97/97 - 29s - loss: 1.4369 - acc: 0.2515 - val_loss: 1.6144 - val_acc: 0.2332 - 29s/epoch - 296ms/step\n",
      "Epoch 15/300\n",
      "97/97 - 29s - loss: 1.4286 - acc: 0.2489 - val_loss: 1.5491 - val_acc: 0.2383 - 29s/epoch - 296ms/step\n",
      "Epoch 16/300\n",
      "97/97 - 29s - loss: 1.4257 - acc: 0.2576 - val_loss: 2.3899 - val_acc: 0.2306 - 29s/epoch - 297ms/step\n",
      "Epoch 17/300\n",
      "97/97 - 29s - loss: 1.4194 - acc: 0.2531 - val_loss: 6.4642 - val_acc: 0.2202 - 29s/epoch - 297ms/step\n",
      "Epoch 18/300\n",
      "97/97 - 29s - loss: 1.4099 - acc: 0.2420 - val_loss: 3.6868 - val_acc: 0.2746 - 29s/epoch - 297ms/step\n",
      "Epoch 19/300\n",
      "97/97 - 29s - loss: 1.4233 - acc: 0.2394 - val_loss: 12.2475 - val_acc: 0.2539 - 29s/epoch - 297ms/step\n",
      "Epoch 20/300\n",
      "97/97 - 29s - loss: 1.4092 - acc: 0.2482 - val_loss: 1.9210 - val_acc: 0.2565 - 29s/epoch - 298ms/step\n",
      "Epoch 21/300\n",
      "97/97 - 29s - loss: 1.4122 - acc: 0.2394 - val_loss: 1.4609 - val_acc: 0.2461 - 29s/epoch - 297ms/step\n",
      "Epoch 22/300\n",
      "97/97 - 29s - loss: 1.4132 - acc: 0.2541 - val_loss: 1.3915 - val_acc: 0.2358 - 29s/epoch - 297ms/step\n",
      "Epoch 23/300\n",
      "97/97 - 29s - loss: 1.4048 - acc: 0.2576 - val_loss: 1.3921 - val_acc: 0.2461 - 29s/epoch - 298ms/step\n",
      "Epoch 24/300\n",
      "97/97 - 29s - loss: 1.4075 - acc: 0.2511 - val_loss: 1.3916 - val_acc: 0.2772 - 29s/epoch - 298ms/step\n",
      "Epoch 25/300\n",
      "97/97 - 29s - loss: 1.4105 - acc: 0.2420 - val_loss: 1.3918 - val_acc: 0.2772 - 29s/epoch - 299ms/step\n",
      "Epoch 26/300\n",
      "97/97 - 29s - loss: 1.4090 - acc: 0.2359 - val_loss: 1.9708 - val_acc: 0.2073 - 29s/epoch - 299ms/step\n",
      "Epoch 27/300\n",
      "97/97 - 29s - loss: 1.4036 - acc: 0.2437 - val_loss: 1.5181 - val_acc: 0.2953 - 29s/epoch - 299ms/step\n",
      "Epoch 28/300\n",
      "97/97 - 29s - loss: 1.4119 - acc: 0.2586 - val_loss: 1.3905 - val_acc: 0.2513 - 29s/epoch - 299ms/step\n",
      "Epoch 29/300\n",
      "97/97 - 29s - loss: 1.4071 - acc: 0.2417 - val_loss: 1.3999 - val_acc: 0.2228 - 29s/epoch - 299ms/step\n",
      "Epoch 30/300\n",
      "97/97 - 29s - loss: 1.4061 - acc: 0.2450 - val_loss: 2.9727 - val_acc: 0.2383 - 29s/epoch - 299ms/step\n",
      "Epoch 31/300\n",
      "97/97 - 29s - loss: 1.4079 - acc: 0.2385 - val_loss: 1.6932 - val_acc: 0.2746 - 29s/epoch - 300ms/step\n",
      "Epoch 32/300\n",
      "97/97 - 29s - loss: 1.4061 - acc: 0.2498 - val_loss: 3.4876 - val_acc: 0.2280 - 29s/epoch - 299ms/step\n",
      "Epoch 33/300\n",
      "97/97 - 29s - loss: 1.4039 - acc: 0.2511 - val_loss: 14.6653 - val_acc: 0.2539 - 29s/epoch - 300ms/step\n",
      "Epoch 34/300\n",
      "97/97 - 29s - loss: 1.4048 - acc: 0.2463 - val_loss: 1.3903 - val_acc: 0.2409 - 29s/epoch - 299ms/step\n",
      "Epoch 35/300\n",
      "97/97 - 29s - loss: 1.4002 - acc: 0.2482 - val_loss: 10.1738 - val_acc: 0.2435 - 29s/epoch - 299ms/step\n",
      "Epoch 36/300\n",
      "97/97 - 29s - loss: 1.3983 - acc: 0.2495 - val_loss: 3.3268 - val_acc: 0.2254 - 29s/epoch - 300ms/step\n",
      "Epoch 37/300\n",
      "97/97 - 29s - loss: 1.4006 - acc: 0.2625 - val_loss: 1.4542 - val_acc: 0.2306 - 29s/epoch - 300ms/step\n",
      "Epoch 38/300\n",
      "97/97 - 29s - loss: 1.4024 - acc: 0.2635 - val_loss: 1.3997 - val_acc: 0.2435 - 29s/epoch - 301ms/step\n",
      "Epoch 39/300\n",
      "97/97 - 29s - loss: 1.3997 - acc: 0.2667 - val_loss: 1.3972 - val_acc: 0.2332 - 29s/epoch - 302ms/step\n",
      "Epoch 40/300\n",
      "97/97 - 29s - loss: 1.4029 - acc: 0.2638 - val_loss: 1.4220 - val_acc: 0.2617 - 29s/epoch - 301ms/step\n",
      "Epoch 41/300\n",
      "97/97 - 29s - loss: 1.4073 - acc: 0.2567 - val_loss: 3.5896 - val_acc: 0.2202 - 29s/epoch - 301ms/step\n",
      "Epoch 42/300\n",
      "97/97 - 29s - loss: 1.3960 - acc: 0.2739 - val_loss: 1.6672 - val_acc: 0.2642 - 29s/epoch - 300ms/step\n",
      "Epoch 43/300\n",
      "97/97 - 29s - loss: 1.4009 - acc: 0.2677 - val_loss: 1.3996 - val_acc: 0.2772 - 29s/epoch - 299ms/step\n",
      "Epoch 44/300\n",
      "97/97 - 29s - loss: 1.4171 - acc: 0.2550 - val_loss: 1.3986 - val_acc: 0.2435 - 29s/epoch - 301ms/step\n",
      "Epoch 45/300\n",
      "97/97 - 29s - loss: 1.4135 - acc: 0.2375 - val_loss: 1.4724 - val_acc: 0.2539 - 29s/epoch - 300ms/step\n",
      "Epoch 46/300\n",
      "97/97 - 29s - loss: 1.4087 - acc: 0.2472 - val_loss: 1.4323 - val_acc: 0.2435 - 29s/epoch - 301ms/step\n",
      "Epoch 47/300\n",
      "97/97 - 29s - loss: 1.4016 - acc: 0.2511 - val_loss: 1.3934 - val_acc: 0.2332 - 29s/epoch - 300ms/step\n",
      "Epoch 48/300\n",
      "97/97 - 29s - loss: 1.3991 - acc: 0.2547 - val_loss: 1.3887 - val_acc: 0.2409 - 29s/epoch - 300ms/step\n",
      "Epoch 49/300\n",
      "97/97 - 29s - loss: 1.4017 - acc: 0.2508 - val_loss: 1.3853 - val_acc: 0.2332 - 29s/epoch - 299ms/step\n",
      "Epoch 50/300\n",
      "97/97 - 29s - loss: 1.3952 - acc: 0.2508 - val_loss: 1.4163 - val_acc: 0.2513 - 29s/epoch - 301ms/step\n",
      "Epoch 51/300\n",
      "97/97 - 29s - loss: 1.3985 - acc: 0.2463 - val_loss: 1.4350 - val_acc: 0.2487 - 29s/epoch - 299ms/step\n",
      "Epoch 52/300\n",
      "97/97 - 29s - loss: 1.4033 - acc: 0.2654 - val_loss: 9.2363 - val_acc: 0.2798 - 29s/epoch - 300ms/step\n",
      "Epoch 53/300\n",
      "97/97 - 29s - loss: 1.4060 - acc: 0.2609 - val_loss: 1.3965 - val_acc: 0.2642 - 29s/epoch - 300ms/step\n",
      "Epoch 54/300\n",
      "97/97 - 29s - loss: 1.4003 - acc: 0.2693 - val_loss: 1.3935 - val_acc: 0.2746 - 29s/epoch - 300ms/step\n",
      "Epoch 55/300\n",
      "97/97 - 29s - loss: 1.3995 - acc: 0.2749 - val_loss: 1.4037 - val_acc: 0.2280 - 29s/epoch - 300ms/step\n",
      "Epoch 56/300\n",
      "97/97 - 29s - loss: 1.3954 - acc: 0.2716 - val_loss: 6.3577 - val_acc: 0.2772 - 29s/epoch - 300ms/step\n",
      "Epoch 57/300\n",
      "97/97 - 29s - loss: 1.3907 - acc: 0.2784 - val_loss: 2.1704 - val_acc: 0.3083 - 29s/epoch - 300ms/step\n",
      "Epoch 58/300\n",
      "97/97 - 29s - loss: 1.3954 - acc: 0.2680 - val_loss: 1.6673 - val_acc: 0.2850 - 29s/epoch - 300ms/step\n",
      "Epoch 59/300\n",
      "97/97 - 29s - loss: 1.3941 - acc: 0.2697 - val_loss: 1.3818 - val_acc: 0.2694 - 29s/epoch - 300ms/step\n",
      "Epoch 60/300\n",
      "97/97 - 29s - loss: 1.3880 - acc: 0.2661 - val_loss: 1.3725 - val_acc: 0.3368 - 29s/epoch - 300ms/step\n",
      "Epoch 61/300\n",
      "97/97 - 29s - loss: 1.3830 - acc: 0.2739 - val_loss: 2.5615 - val_acc: 0.2979 - 29s/epoch - 300ms/step\n",
      "Epoch 62/300\n",
      "97/97 - 29s - loss: 1.3923 - acc: 0.2693 - val_loss: 2.1200 - val_acc: 0.2642 - 29s/epoch - 300ms/step\n",
      "Epoch 63/300\n",
      "97/97 - 29s - loss: 1.3783 - acc: 0.2794 - val_loss: 1.3994 - val_acc: 0.2927 - 29s/epoch - 300ms/step\n",
      "Epoch 64/300\n",
      "97/97 - 29s - loss: 1.3773 - acc: 0.2742 - val_loss: 1.3822 - val_acc: 0.2720 - 29s/epoch - 302ms/step\n",
      "Epoch 65/300\n",
      "97/97 - 29s - loss: 1.3782 - acc: 0.2814 - val_loss: 1.3850 - val_acc: 0.2668 - 29s/epoch - 303ms/step\n",
      "Epoch 66/300\n",
      "97/97 - 29s - loss: 1.3827 - acc: 0.2882 - val_loss: 1.3866 - val_acc: 0.2746 - 29s/epoch - 302ms/step\n",
      "Epoch 67/300\n",
      "97/97 - 29s - loss: 1.3835 - acc: 0.2859 - val_loss: 1.3855 - val_acc: 0.2850 - 29s/epoch - 304ms/step\n",
      "Epoch 68/300\n",
      "97/97 - 29s - loss: 1.3793 - acc: 0.2895 - val_loss: 1.4027 - val_acc: 0.2876 - 29s/epoch - 299ms/step\n",
      "Epoch 69/300\n",
      "97/97 - 29s - loss: 1.3706 - acc: 0.3044 - val_loss: 1.7894 - val_acc: 0.2824 - 29s/epoch - 297ms/step\n",
      "Epoch 70/300\n",
      "97/97 - 29s - loss: 1.3653 - acc: 0.3216 - val_loss: 1.4905 - val_acc: 0.2591 - 29s/epoch - 298ms/step\n",
      "Epoch 71/300\n",
      "97/97 - 29s - loss: 1.3495 - acc: 0.3285 - val_loss: 1.5789 - val_acc: 0.2409 - 29s/epoch - 297ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 72/300\n",
      "97/97 - 29s - loss: 1.3591 - acc: 0.3197 - val_loss: 1.4225 - val_acc: 0.2720 - 29s/epoch - 302ms/step\n",
      "Epoch 73/300\n",
      "97/97 - 29s - loss: 1.3296 - acc: 0.3519 - val_loss: 1.3549 - val_acc: 0.3420 - 29s/epoch - 299ms/step\n",
      "Epoch 74/300\n",
      "97/97 - 29s - loss: 1.3195 - acc: 0.3626 - val_loss: 1.3741 - val_acc: 0.2979 - 29s/epoch - 297ms/step\n",
      "Epoch 75/300\n",
      "97/97 - 29s - loss: 1.3065 - acc: 0.3694 - val_loss: 1.7451 - val_acc: 0.2902 - 29s/epoch - 296ms/step\n",
      "Epoch 76/300\n",
      "97/97 - 29s - loss: 1.2953 - acc: 0.3778 - val_loss: 1.3505 - val_acc: 0.3523 - 29s/epoch - 296ms/step\n",
      "Epoch 77/300\n",
      "97/97 - 29s - loss: 1.2895 - acc: 0.3733 - val_loss: 1.3381 - val_acc: 0.3368 - 29s/epoch - 296ms/step\n",
      "Epoch 78/300\n",
      "97/97 - 29s - loss: 1.2828 - acc: 0.3772 - val_loss: 1.3794 - val_acc: 0.3316 - 29s/epoch - 296ms/step\n",
      "Epoch 79/300\n",
      "97/97 - 29s - loss: 1.2762 - acc: 0.3983 - val_loss: 1.6010 - val_acc: 0.2876 - 29s/epoch - 295ms/step\n",
      "Epoch 80/300\n",
      "97/97 - 29s - loss: 1.2672 - acc: 0.3977 - val_loss: 1.8563 - val_acc: 0.2953 - 29s/epoch - 294ms/step\n",
      "Epoch 81/300\n",
      "97/97 - 29s - loss: 1.2525 - acc: 0.4032 - val_loss: 1.4971 - val_acc: 0.3549 - 29s/epoch - 294ms/step\n",
      "Epoch 82/300\n",
      "97/97 - 29s - loss: 1.2504 - acc: 0.4081 - val_loss: 1.4862 - val_acc: 0.3031 - 29s/epoch - 295ms/step\n",
      "Epoch 83/300\n",
      "97/97 - 28s - loss: 1.2403 - acc: 0.4240 - val_loss: 1.4348 - val_acc: 0.3238 - 28s/epoch - 294ms/step\n",
      "Epoch 84/300\n",
      "97/97 - 29s - loss: 1.2244 - acc: 0.4276 - val_loss: 1.5118 - val_acc: 0.3808 - 29s/epoch - 294ms/step\n",
      "Epoch 85/300\n",
      "97/97 - 29s - loss: 1.2212 - acc: 0.4146 - val_loss: 1.4951 - val_acc: 0.3472 - 29s/epoch - 294ms/step\n",
      "Epoch 86/300\n",
      "97/97 - 29s - loss: 1.2090 - acc: 0.4415 - val_loss: 1.5526 - val_acc: 0.3290 - 29s/epoch - 294ms/step\n",
      "Epoch 87/300\n",
      "97/97 - 28s - loss: 1.2201 - acc: 0.4305 - val_loss: 1.6617 - val_acc: 0.2953 - 28s/epoch - 293ms/step\n",
      "Epoch 88/300\n",
      "97/97 - 28s - loss: 1.2137 - acc: 0.4392 - val_loss: 1.3969 - val_acc: 0.3731 - 28s/epoch - 293ms/step\n",
      "Epoch 89/300\n",
      "97/97 - 28s - loss: 1.1736 - acc: 0.4532 - val_loss: 1.4827 - val_acc: 0.3161 - 28s/epoch - 293ms/step\n",
      "Epoch 90/300\n",
      "97/97 - 29s - loss: 1.1723 - acc: 0.4656 - val_loss: 1.4849 - val_acc: 0.3342 - 29s/epoch - 297ms/step\n",
      "Epoch 91/300\n"
     ]
    }
   ],
   "source": [
    "epochs = 300\n",
    "\n",
    "#compila e treina o modelo com os dados carregados\n",
    "new_model.compile(loss='sparse_categorical_crossentropy', metrics=['acc'], optimizer=adam)\n",
    "model_trained = new_model.fit(train_x, train_y,epochs=epochs,verbose=2,validation_data=(validation_x, validation_y),shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getLayerIndexByName(model, layername):\n",
    "    for idx, layer in enumerate(model.layers):\n",
    "        if layer.name == layername:\n",
    "            return idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(getLayerIndexByName(new_model, 'flatten_1')) #just used to get the index of flatten layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = f'resnet50-justfractal_baseline-holdout-{epochs}epochs_normalized.npy'\n",
    "new_model.save(model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Random Forest - flatting**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_model_rf = keras.Model(inputs=new_model.input, outputs=new_model.get_layer(index=9).output)\n",
    "featureVector = new_model_rf.predict(train_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "featureVector2 = new_model_rf.predict(test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(featureVector.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf=RandomForestClassifier(n_estimators=100)\n",
    "\n",
    "clf.fit(featureVector,train_y)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred=clf.predict(featureVector2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "featureVector.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "print(\"Accuracy:\",metrics.accuracy_score(test_y, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = DecisionTreeClassifier(random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "v2tUu9UW4S_S"
   },
   "source": [
    "# **Testes**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-02BWWgF4V9h"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "accuracy = model_trained.history['acc']\n",
    "val_accuracy = model_trained.history['val_acc']\n",
    "loss = model_trained.history['loss']\n",
    "val_loss = model_trained.history['val_loss']\n",
    "epochs = range(len(accuracy))\n",
    "plt.plot(epochs, accuracy, 'b', label='Acurácia de treino')\n",
    "plt.plot(epochs, val_accuracy, 'g', label='Acurácia de validação')\n",
    "plt.title('Acurácia de treino e validação')\n",
    "plt.legend()\n",
    "plt.figure()\n",
    "plt.plot(epochs, loss, 'b', label='Perda no treino')\n",
    "plt.plot(epochs, val_loss, 'g', label='Perda na validação')\n",
    "plt.title('Perda na validação e treino')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "On7_hNmrOysp"
   },
   "outputs": [],
   "source": [
    "#avalia a fase de teste\n",
    "\n",
    "model_loss, model_accuracy = new_model.evaluate(test_x, test_y, verbose=1)\n",
    "\n",
    "#mostra o resultado\n",
    "print('Test loss:', model_loss)\n",
    "print('Test accuracy:', model_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uGYRlhnq8wsF"
   },
   "outputs": [],
   "source": [
    "#faz a predição das imagens\n",
    "\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "pred = new_model.predict(test_x, verbose=0)\n",
    "\n",
    "pred_probs = np.argmax(pred,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Vt4jZ2jB8ygE"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9gx5yvuU84UC"
   },
   "outputs": [],
   "source": [
    "cm = confusion_matrix(test_y, pred_probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NUrE8yfU86OL"
   },
   "outputs": [],
   "source": [
    "#gera os valores de falso positivo, falso negativo, verdadeiro positivo e verdadeiro negativo\n",
    "fp = cm.sum(axis=0) - np.diag(cm)  \n",
    "fn = cm.sum(axis=1) - np.diag(cm)\n",
    "tp = np.diag(cm)\n",
    "tn = cm.sum() - (fp + fn + tp)\n",
    "\n",
    "f1score = f1_score(test_y, pred_probs, average='weighted')\n",
    "sensitivity = tp / (tp + fn)\n",
    "specificity = tn / (tn + fp)\n",
    "accuracy    = (tp + tn) / (tp + tn + fp + fn)\n",
    "precision   = tp / (tp + fp)\n",
    "\n",
    "\n",
    "print(\"F1 Score:\", f1score)\n",
    "print(\"Sensitivity:\", sensitivity)\n",
    "print(\"Specificity:\", specificity)\n",
    "print(\"Precision:  \", precision)\n",
    "print(\"Accuracy:   \", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "covid_alex_holdout_cropping_tgo.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
