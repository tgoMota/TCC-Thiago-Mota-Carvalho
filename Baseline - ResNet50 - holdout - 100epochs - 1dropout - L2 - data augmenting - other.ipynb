{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "on-xhn6xYqDo"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "Zq5nydmlidrt"
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import glob\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications import *\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.models import *\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import *\n",
    "from tensorflow.keras.callbacks import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "CLASS_NAMES= ['healthy', 'mild', 'moderate', 'severe']\n",
    "IMG_HEIGHT = 128\n",
    "IMG_WIDTH = 128\n",
    "CHANNELS = 3\n",
    "NUM_CLASSES = len(CLASS_NAMES)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yfeZvMIEDOwS"
   },
   "source": [
    "# **ResNET**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "98Cf8ZeSEbCU"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TOTAL_IMAGES =  2368\n"
     ]
    }
   ],
   "source": [
    "#load data\n",
    "data_x = np.load('data_x_aumentated_normalized.npy') #images\n",
    "data_y = np.load('data_y_aumentated_normalized.npy') #labels\n",
    "TOTAL_IMAGES = len(data_y)\n",
    "print(\"TOTAL_IMAGES = \", TOTAL_IMAGES)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Splitting data in train - validation - test**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#percentage of the dataset which will be on TRAIN - TEST - VALIDATION\n",
    "TRAIN_PERCENTAGE = 0.8\n",
    "TEST_PERCENTAGE = 0.1\n",
    "VALIDATION_PERCENTAGE = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = int(TRAIN_PERCENTAGE * TOTAL_IMAGES)\n",
    "test_size = int(TEST_PERCENTAGE * TOTAL_IMAGES)\n",
    "validation_size = int(VALIDATION_PERCENTAGE * TOTAL_IMAGES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = data_x[:train_size]\n",
    "train_y = data_y[:train_size]\n",
    "data_x = data_x[train_size:]\n",
    "data_y = data_y[train_size:]\n",
    "\n",
    "test_x = data_x[:test_size]\n",
    "test_y = data_y[:test_size]\n",
    "data_x = data_x[test_size:]\n",
    "data_y = data_y[test_size:]\n",
    "\n",
    "validation_x = data_x #all the remainder we can let on validation\n",
    "validation_y = data_y\n",
    "del data_x\n",
    "del data_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_size =  1894\n",
      "test_size =  236\n",
      "validation_size =  238\n"
     ]
    }
   ],
   "source": [
    "print(\"train_size = \", len(train_y))\n",
    "print(\"test_size = \", len(test_y))\n",
    "print(\"validation_size = \", len(validation_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "BiIjdq89J1uJ"
   },
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Activation, Dropout, Flatten, Conv2D, MaxPooling2D\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.regularizers import l1\n",
    "from tensorflow.keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "j0vHxhMjLyhJ",
    "outputId": "e5ec2803-8f76-4719-e279-27c52eb8d72d"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.layers import Input, Add, Dense, Activation, ZeroPadding2D, BatchNormalization, Flatten, Conv2D, AveragePooling2D, MaxPooling2D, GlobalMaxPooling2D\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from IPython.display import SVG\n",
    "import scipy.misc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from tensorflow.keras.applications import EfficientNetB0\n",
    "# from tensorflow.keras.applications import EfficientNetB1\n",
    "# from tensorflow.keras.applications import EfficientNetB2\n",
    "# from tensorflow.keras.applications import EfficientNetB3\n",
    "# from tensorflow.keras.applications import EfficientNetB4\n",
    "# from tensorflow.keras.applications import EfficientNetB5\n",
    "# from tensorflow.keras.applications import EfficientNetB6\n",
    "# from tensorflow.keras.applications import EfficientNetB7\n",
    "# from tensorflow.keras.applications import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tmcle\\.conda\\envs\\tf\\lib\\site-packages\\keras\\backend.py:451: UserWarning: `tf.keras.backend.set_learning_phase` is deprecated and will be removed after 2020-10-11. To update it, simply pass a True/False value to the `training` argument of the `__call__` method of your layer or model.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import tensorflow.keras.backend as K\n",
    "K.set_image_data_format('channels_last')\n",
    "K.set_learning_phase(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.applications.ResNet50(\n",
    "    include_top=False,\n",
    "    weights=\"imagenet\",\n",
    "    input_tensor=None,\n",
    "    input_shape=(IMG_HEIGHT,IMG_WIDTH, CHANNELS),\n",
    "    pooling=None,\n",
    "    classes=NUM_CLASSES,\n",
    "   # classifier_activation=\"softmax\",\n",
    "#    **kwargs\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tmcle\\.conda\\envs\\tf\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras import models\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "new_model = models.Sequential()\n",
    "new_model.add(model)\n",
    "#3rd conv layer\n",
    "new_model.add(tf.keras.layers.Conv2D(32, 3, padding=\"same\"))\n",
    "new_model.add(tf.keras.layers.BatchNormalization())\n",
    "new_model.add(tf.keras.layers.Activation(\"relu\"))\n",
    "new_model.add(tf.keras.layers.MaxPooling2D(2))\n",
    "#4th conv layer\n",
    "new_model.add(tf.keras.layers.Conv2D(64, 3, padding=\"same\"))\n",
    "new_model.add(tf.keras.layers.BatchNormalization())\n",
    "new_model.add(tf.keras.layers.Activation(\"relu\"))\n",
    "new_model.add(tf.keras.layers.MaxPooling2D(2))\n",
    "#Flatten Layer\n",
    "new_model.add(tf.keras.layers.Flatten())\n",
    "\n",
    "new_model.add(tf.keras.layers.Dense(128, kernel_regularizer =tf.keras.regularizers.l2( l=0.01)))\n",
    "new_model.add(tf.keras.layers.BatchNormalization())\n",
    "new_model.add(tf.keras.layers.Activation(\"relu\"))\n",
    "new_model.add(tf.keras.layers.Dropout(0.2))\n",
    "#new_model.add(tf.keras.layers.l2( l=0.01))\n",
    "#new_model.add(layers.GlobalAveragePooling2D())\n",
    "#output Dense Layer\n",
    "new_model.add(tf.keras.layers.Dense(NUM_CLASSES))\n",
    "new_model.add(tf.keras.layers.Activation('softmax'))\n",
    "adam = tf.keras.optimizers.Adam(lr=0.001)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " resnet50 (Functional)       (None, 4, 4, 2048)        23587712  \n",
      "                                                                 \n",
      " conv2d (Conv2D)             (None, 4, 4, 32)          589856    \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 4, 4, 32)         128       \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " activation (Activation)     (None, 4, 4, 32)          0         \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 2, 2, 32)         0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 2, 2, 64)          18496     \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 2, 2, 64)         256       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " activation_1 (Activation)   (None, 2, 2, 64)          0         \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 1, 1, 64)         0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 64)                0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 128)               8320      \n",
      "                                                                 \n",
      " batch_normalization_2 (Batc  (None, 128)              512       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " activation_2 (Activation)   (None, 128)               0         \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 128)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 4)                 516       \n",
      "                                                                 \n",
      " activation_3 (Activation)   (None, 4)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 24,205,796\n",
      "Trainable params: 24,152,228\n",
      "Non-trainable params: 53,568\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "new_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "60/60 [==============================] - 30s 332ms/step - loss: 1.6226 - acc: 0.6695 - val_loss: 12.8364 - val_acc: 0.2143\n",
      "Epoch 2/100\n",
      "60/60 [==============================] - 17s 289ms/step - loss: 1.0697 - acc: 0.8342 - val_loss: 2.3872 - val_acc: 0.2899\n",
      "Epoch 3/100\n",
      "60/60 [==============================] - 17s 285ms/step - loss: 0.7759 - acc: 0.8997 - val_loss: 4.2558 - val_acc: 0.2437\n",
      "Epoch 4/100\n",
      "60/60 [==============================] - 17s 286ms/step - loss: 0.6095 - acc: 0.9208 - val_loss: 3.9730 - val_acc: 0.2437\n",
      "Epoch 5/100\n",
      "60/60 [==============================] - 17s 285ms/step - loss: 0.5430 - acc: 0.9139 - val_loss: 3.2074 - val_acc: 0.2437\n",
      "Epoch 6/100\n",
      "60/60 [==============================] - 17s 286ms/step - loss: 0.4282 - acc: 0.9340 - val_loss: 4.1885 - val_acc: 0.2437\n",
      "Epoch 7/100\n",
      "60/60 [==============================] - 17s 286ms/step - loss: 0.3430 - acc: 0.9409 - val_loss: 3.3195 - val_acc: 0.2437\n",
      "Epoch 8/100\n",
      "60/60 [==============================] - 17s 287ms/step - loss: 0.2663 - acc: 0.9583 - val_loss: 2.7094 - val_acc: 0.2311\n",
      "Epoch 9/100\n",
      "60/60 [==============================] - 17s 289ms/step - loss: 0.2134 - acc: 0.9662 - val_loss: 4.1376 - val_acc: 0.2437\n",
      "Epoch 10/100\n",
      "60/60 [==============================] - 18s 294ms/step - loss: 0.2086 - acc: 0.9583 - val_loss: 5.3245 - val_acc: 0.2437\n",
      "Epoch 11/100\n",
      "60/60 [==============================] - 18s 292ms/step - loss: 0.1584 - acc: 0.9715 - val_loss: 6.4743 - val_acc: 0.2437\n",
      "Epoch 12/100\n",
      "60/60 [==============================] - 17s 291ms/step - loss: 0.1655 - acc: 0.9593 - val_loss: 4.6345 - val_acc: 0.2437\n",
      "Epoch 13/100\n",
      "60/60 [==============================] - 17s 288ms/step - loss: 0.1542 - acc: 0.9641 - val_loss: 3.9630 - val_acc: 0.2857\n",
      "Epoch 14/100\n",
      "60/60 [==============================] - 17s 288ms/step - loss: 0.1062 - acc: 0.9784 - val_loss: 5.5125 - val_acc: 0.2521\n",
      "Epoch 15/100\n",
      "60/60 [==============================] - 17s 289ms/step - loss: 0.1007 - acc: 0.9794 - val_loss: 4.2368 - val_acc: 0.3487\n",
      "Epoch 16/100\n",
      "60/60 [==============================] - 17s 289ms/step - loss: 0.0502 - acc: 0.9926 - val_loss: 3.5481 - val_acc: 0.3361\n",
      "Epoch 17/100\n",
      "60/60 [==============================] - 17s 289ms/step - loss: 0.0861 - acc: 0.9842 - val_loss: 5.5530 - val_acc: 0.3571\n",
      "Epoch 18/100\n",
      "60/60 [==============================] - 17s 289ms/step - loss: 0.0688 - acc: 0.9884 - val_loss: 4.2305 - val_acc: 0.3866\n",
      "Epoch 19/100\n",
      "60/60 [==============================] - 17s 289ms/step - loss: 0.0400 - acc: 0.9952 - val_loss: 3.6636 - val_acc: 0.4286\n",
      "Epoch 20/100\n",
      "60/60 [==============================] - 17s 290ms/step - loss: 0.0208 - acc: 1.0000 - val_loss: 2.8958 - val_acc: 0.5084\n",
      "Epoch 21/100\n",
      "60/60 [==============================] - 17s 291ms/step - loss: 0.0152 - acc: 1.0000 - val_loss: 1.1740 - val_acc: 0.7017\n",
      "Epoch 22/100\n",
      "60/60 [==============================] - 18s 292ms/step - loss: 0.0113 - acc: 1.0000 - val_loss: 0.6609 - val_acc: 0.8109\n",
      "Epoch 23/100\n",
      "60/60 [==============================] - 17s 289ms/step - loss: 0.0086 - acc: 1.0000 - val_loss: 0.2972 - val_acc: 0.8992\n",
      "Epoch 24/100\n",
      "60/60 [==============================] - 17s 290ms/step - loss: 0.0070 - acc: 1.0000 - val_loss: 0.1655 - val_acc: 0.9496\n",
      "Epoch 25/100\n",
      "60/60 [==============================] - 17s 291ms/step - loss: 0.0055 - acc: 1.0000 - val_loss: 0.1429 - val_acc: 0.9664\n",
      "Epoch 26/100\n",
      "60/60 [==============================] - 17s 291ms/step - loss: 0.0042 - acc: 1.0000 - val_loss: 0.1275 - val_acc: 0.9664\n",
      "Epoch 27/100\n",
      "60/60 [==============================] - 17s 291ms/step - loss: 0.0032 - acc: 1.0000 - val_loss: 0.1255 - val_acc: 0.9622\n",
      "Epoch 28/100\n",
      "60/60 [==============================] - 17s 291ms/step - loss: 0.0027 - acc: 1.0000 - val_loss: 0.1262 - val_acc: 0.9580\n",
      "Epoch 29/100\n",
      "60/60 [==============================] - 17s 291ms/step - loss: 0.0022 - acc: 1.0000 - val_loss: 0.1269 - val_acc: 0.9580\n",
      "Epoch 30/100\n",
      "60/60 [==============================] - 17s 291ms/step - loss: 0.0018 - acc: 1.0000 - val_loss: 0.1258 - val_acc: 0.9538\n",
      "Epoch 31/100\n",
      "60/60 [==============================] - 17s 292ms/step - loss: 0.0015 - acc: 1.0000 - val_loss: 0.1301 - val_acc: 0.9580\n",
      "Epoch 32/100\n",
      "60/60 [==============================] - 17s 292ms/step - loss: 0.0013 - acc: 1.0000 - val_loss: 0.1337 - val_acc: 0.9622\n",
      "Epoch 33/100\n",
      "60/60 [==============================] - 17s 292ms/step - loss: 0.0012 - acc: 1.0000 - val_loss: 0.1325 - val_acc: 0.9580\n",
      "Epoch 34/100\n",
      "60/60 [==============================] - 18s 292ms/step - loss: 0.0011 - acc: 1.0000 - val_loss: 0.1233 - val_acc: 0.9622\n",
      "Epoch 35/100\n",
      "60/60 [==============================] - 18s 293ms/step - loss: 0.0011 - acc: 1.0000 - val_loss: 0.1206 - val_acc: 0.9622\n",
      "Epoch 36/100\n",
      "60/60 [==============================] - 18s 292ms/step - loss: 0.0013 - acc: 1.0000 - val_loss: 0.1369 - val_acc: 0.9664\n",
      "Epoch 37/100\n",
      "60/60 [==============================] - 17s 292ms/step - loss: 0.0010 - acc: 1.0000 - val_loss: 0.1275 - val_acc: 0.9622\n",
      "Epoch 38/100\n",
      "60/60 [==============================] - 18s 292ms/step - loss: 9.0015e-04 - acc: 1.0000 - val_loss: 0.1317 - val_acc: 0.9580\n",
      "Epoch 39/100\n",
      "60/60 [==============================] - 18s 292ms/step - loss: 7.7423e-04 - acc: 1.0000 - val_loss: 0.1362 - val_acc: 0.9580\n",
      "Epoch 40/100\n",
      "60/60 [==============================] - 17s 291ms/step - loss: 7.3984e-04 - acc: 1.0000 - val_loss: 0.1320 - val_acc: 0.9622\n",
      "Epoch 41/100\n",
      "60/60 [==============================] - 18s 293ms/step - loss: 6.9977e-04 - acc: 1.0000 - val_loss: 0.1336 - val_acc: 0.9622\n",
      "Epoch 42/100\n",
      "60/60 [==============================] - 18s 294ms/step - loss: 6.7577e-04 - acc: 1.0000 - val_loss: 0.1353 - val_acc: 0.9580\n",
      "Epoch 43/100\n",
      "60/60 [==============================] - 18s 292ms/step - loss: 6.4345e-04 - acc: 1.0000 - val_loss: 0.1319 - val_acc: 0.9664\n",
      "Epoch 44/100\n",
      "60/60 [==============================] - 17s 292ms/step - loss: 6.3732e-04 - acc: 1.0000 - val_loss: 0.1279 - val_acc: 0.9622\n",
      "Epoch 45/100\n",
      "60/60 [==============================] - 19s 321ms/step - loss: 6.2069e-04 - acc: 1.0000 - val_loss: 0.1337 - val_acc: 0.9622\n",
      "Epoch 46/100\n",
      "60/60 [==============================] - 19s 324ms/step - loss: 5.8806e-04 - acc: 1.0000 - val_loss: 0.1294 - val_acc: 0.9580\n",
      "Epoch 47/100\n",
      "60/60 [==============================] - 19s 324ms/step - loss: 5.8536e-04 - acc: 1.0000 - val_loss: 0.1429 - val_acc: 0.9622\n",
      "Epoch 48/100\n",
      "60/60 [==============================] - 19s 323ms/step - loss: 5.6036e-04 - acc: 1.0000 - val_loss: 0.1491 - val_acc: 0.9622\n",
      "Epoch 49/100\n",
      "60/60 [==============================] - 19s 324ms/step - loss: 5.6191e-04 - acc: 1.0000 - val_loss: 0.1378 - val_acc: 0.9580\n",
      "Epoch 50/100\n",
      "60/60 [==============================] - 19s 324ms/step - loss: 5.1193e-04 - acc: 1.0000 - val_loss: 0.1282 - val_acc: 0.9622\n",
      "Epoch 51/100\n",
      "60/60 [==============================] - 19s 324ms/step - loss: 5.0702e-04 - acc: 1.0000 - val_loss: 0.1249 - val_acc: 0.9664\n",
      "Epoch 52/100\n",
      "60/60 [==============================] - 20s 328ms/step - loss: 5.0016e-04 - acc: 1.0000 - val_loss: 0.1344 - val_acc: 0.9664\n",
      "Epoch 53/100\n",
      "60/60 [==============================] - 20s 332ms/step - loss: 5.0611e-04 - acc: 1.0000 - val_loss: 0.1290 - val_acc: 0.9622\n",
      "Epoch 54/100\n",
      "60/60 [==============================] - 19s 325ms/step - loss: 5.1811e-04 - acc: 1.0000 - val_loss: 0.1272 - val_acc: 0.9622\n",
      "Epoch 55/100\n",
      "60/60 [==============================] - 20s 330ms/step - loss: 5.0748e-04 - acc: 1.0000 - val_loss: 0.1432 - val_acc: 0.9664\n",
      "Epoch 56/100\n",
      "60/60 [==============================] - 20s 329ms/step - loss: 4.5650e-04 - acc: 1.0000 - val_loss: 0.1379 - val_acc: 0.9664\n",
      "Epoch 57/100\n",
      "60/60 [==============================] - 20s 330ms/step - loss: 4.3667e-04 - acc: 1.0000 - val_loss: 0.1351 - val_acc: 0.9664\n",
      "Epoch 58/100\n",
      "60/60 [==============================] - 20s 327ms/step - loss: 4.5935e-04 - acc: 1.0000 - val_loss: 0.1369 - val_acc: 0.9580\n",
      "Epoch 59/100\n",
      "60/60 [==============================] - 20s 330ms/step - loss: 4.2158e-04 - acc: 1.0000 - val_loss: 0.1423 - val_acc: 0.9622\n",
      "Epoch 60/100\n",
      "60/60 [==============================] - 20s 326ms/step - loss: 4.4638e-04 - acc: 1.0000 - val_loss: 0.1447 - val_acc: 0.9664\n",
      "Epoch 61/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60/60 [==============================] - 20s 327ms/step - loss: 4.2349e-04 - acc: 1.0000 - val_loss: 0.1337 - val_acc: 0.9664\n",
      "Epoch 62/100\n",
      "60/60 [==============================] - 20s 327ms/step - loss: 4.4029e-04 - acc: 1.0000 - val_loss: 0.1405 - val_acc: 0.9622\n",
      "Epoch 63/100\n",
      "60/60 [==============================] - 17s 289ms/step - loss: 4.0222e-04 - acc: 1.0000 - val_loss: 0.1310 - val_acc: 0.9622\n",
      "Epoch 64/100\n",
      "60/60 [==============================] - 19s 320ms/step - loss: 4.2182e-04 - acc: 1.0000 - val_loss: 0.1232 - val_acc: 0.9622\n",
      "Epoch 65/100\n",
      "60/60 [==============================] - 20s 328ms/step - loss: 3.9018e-04 - acc: 1.0000 - val_loss: 0.1489 - val_acc: 0.9664\n",
      "Epoch 66/100\n",
      "60/60 [==============================] - 20s 329ms/step - loss: 3.5706e-04 - acc: 1.0000 - val_loss: 0.1494 - val_acc: 0.9664\n",
      "Epoch 67/100\n",
      "60/60 [==============================] - 20s 328ms/step - loss: 3.4383e-04 - acc: 1.0000 - val_loss: 0.1421 - val_acc: 0.9622\n",
      "Epoch 68/100\n",
      "60/60 [==============================] - 20s 326ms/step - loss: 3.8534e-04 - acc: 1.0000 - val_loss: 0.1408 - val_acc: 0.9622\n",
      "Epoch 69/100\n",
      "45/60 [=====================>........] - ETA: 4s - loss: 3.5029e-04 - acc: 1.0000"
     ]
    }
   ],
   "source": [
    "epochs = 100\n",
    "\n",
    "#compila e treina o modelo com os dados carregados\n",
    "new_model.compile(loss='sparse_categorical_crossentropy', metrics=['acc'], optimizer=adam)\n",
    "model_trained = new_model.fit(train_x, train_y,epochs=epochs,verbose=1,validation_data=(validation_x, validation_y),shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getLayerIndexByName(model, layername):\n",
    "    for idx, layer in enumerate(model.layers):\n",
    "        if layer.name == layername:\n",
    "            return idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(getLayerIndexByName(new_model, 'flatten_1')) #just used to get the index of flatten layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = f'displasys_resnet50-baseline-holdout-{epochs}epochs_normalized.npy'\n",
    "model.save(model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Random Forest - flatting**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_model_rf = keras.Model(inputs=new_model.input, outputs=new_model.get_layer(index=9).output)\n",
    "featureVector = new_model_rf.predict(train_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "featureVector2 = new_model_rf.predict(test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(featureVector.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf=RandomForestClassifier(n_estimators=100)\n",
    "\n",
    "clf.fit(featureVector,train_y)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred=clf.predict(featureVector2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "featureVector.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "print(\"Accuracy:\",metrics.accuracy_score(test_y, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = DecisionTreeClassifier(random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "v2tUu9UW4S_S"
   },
   "source": [
    "# **Testes**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-02BWWgF4V9h"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "accuracy = model_trained.history['acc']\n",
    "val_accuracy = model_trained.history['val_acc']\n",
    "loss = model_trained.history['loss']\n",
    "val_loss = model_trained.history['val_loss']\n",
    "epochs = range(len(accuracy))\n",
    "plt.plot(epochs, accuracy, 'b', label='Acurácia de treino')\n",
    "plt.plot(epochs, val_accuracy, 'g', label='Acurácia de validação')\n",
    "plt.title('Acurácia de treino e validação')\n",
    "plt.legend()\n",
    "plt.figure()\n",
    "plt.plot(epochs, loss, 'b', label='Perda no treino')\n",
    "plt.plot(epochs, val_loss, 'g', label='Perda na validação')\n",
    "plt.title('Perda na validação e treino')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "On7_hNmrOysp"
   },
   "outputs": [],
   "source": [
    "#avalia a fase de teste\n",
    "\n",
    "model_loss, model_accuracy = new_model.evaluate(test_x, test_y, verbose=1)\n",
    "\n",
    "#mostra o resultado\n",
    "print('Test loss:', model_loss)\n",
    "print('Test accuracy:', model_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uGYRlhnq8wsF"
   },
   "outputs": [],
   "source": [
    "#faz a predição das imagens\n",
    "\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "pred = new_model.predict(test_x, verbose=0)\n",
    "\n",
    "pred_probs = np.argmax(pred,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Vt4jZ2jB8ygE"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9gx5yvuU84UC"
   },
   "outputs": [],
   "source": [
    "cm = confusion_matrix(test_y, pred_probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NUrE8yfU86OL"
   },
   "outputs": [],
   "source": [
    "#gera os valores de falso positivo, falso negativo, verdadeiro positivo e verdadeiro negativo\n",
    "fp = cm.sum(axis=0) - np.diag(cm)  \n",
    "fn = cm.sum(axis=1) - np.diag(cm)\n",
    "tp = np.diag(cm)\n",
    "tn = cm.sum() - (fp + fn + tp)\n",
    "\n",
    "f1score = f1_score(test_y, pred_probs, average='weighted')\n",
    "sensitivity = tp / (tp + fn)\n",
    "specificity = tn / (tn + fp)\n",
    "accuracy    = (tp + tn) / (tp + tn + fp + fn)\n",
    "precision   = tp / (tp + fp)\n",
    "\n",
    "\n",
    "print(\"F1 Score:\", f1score)\n",
    "print(\"Sensitivity:\", sensitivity)\n",
    "print(\"Specificity:\", specificity)\n",
    "print(\"Precision:  \", precision)\n",
    "print(\"Accuracy:   \", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "covid_alex_holdout_cropping_tgo.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
